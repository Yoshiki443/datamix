{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "### オンライン学習を導入する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### データの前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(443)\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 学習用データ\n",
    "DATA = pd.read_csv(\"train_data.csv\")\n",
    "TEST = pd.read_csv(\"test_data.csv\")\n",
    "DATA = pd.concat([DATA,TEST]).reset_index(drop=True)\n",
    "\n",
    "# 使うデータを限定\n",
    "use_valiable = [\"DateTime\",\"VIS\",\"VIS_CAT\",\"FG\",\"PRCP_P24HR\",\\\n",
    "                \"RH_SFC\",\"TMP_SFC\",\"TD_SFC\",\"PRES_SFC\",\"LCDC_SFC\",\"MCDC_SFC\",\"HCDC_SFC\",\\\n",
    "                \"WSPD_SFC\",\"WDIR_SFC\",\"APCP_SFC\",\"TimeRange\",\"MONTH\",\\\n",
    "#                 \"D_PRES_SFC\",\"D_TMP_SFC\",\"D_TD_SFC\",\\\n",
    "                \"LL_VWS1\",\"LL_VWS2\",\"LL_STBL1\",\"LL_STBL2\",\"WARMER_RA\",\\\n",
    "                \"RH_1000\",\"VVEL_1000\",\"WSPD_1000\",\"RH_975\",\"VVEL_975\",\"WSPD_975\",\\\n",
    "                \"RH_950\",\"VVEL_950\",\"WSPD_950\",\"RH_850\",\"RH_700\",\"RH_500\",\"RH_300\"]\n",
    "DATA = DATA[use_valiable]\n",
    "\n",
    "# カテゴリー変数はダミー化\n",
    "cat_val = ['WDIR_SFC', 'TimeRange', 'MONTH']\n",
    "DATA = pd.get_dummies(data=DATA, columns=cat_val)\n",
    "\n",
    "# 雨が降った後の夜間に霧が出やすいことを表現できるかもしれない\n",
    "DATA[\"Time_12-14_RAp24hr\"] = DATA[\"PRCP_P24HR\"] * DATA[\"TimeRange_12-14\"]\n",
    "DATA[\"Time_15-17_RAp24hr\"] = DATA[\"PRCP_P24HR\"] * DATA[\"TimeRange_15-17\"]\n",
    "DATA[\"Time_18-20_RAp24hr\"] = DATA[\"PRCP_P24HR\"] * DATA[\"TimeRange_18-20\"]\n",
    "DATA[\"Time_21-23_RAp24hr\"] = DATA[\"PRCP_P24HR\"] * DATA[\"TimeRange_21-23\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chainerで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/calmtree443/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from chainer import Chain, Variable, configuration\n",
    "import chainer.links as L\n",
    "import chainer.functions as F\n",
    "from chainer.optimizers import Adam, MomentumSGD, RMSprop, SGD\n",
    "from chainer.datasets import TupleDataset\n",
    "from chainer.iterators import SerialIterator\n",
    "from chainer.training import StandardUpdater\n",
    "from chainer.training import Trainer\n",
    "from chainer.training.extensions import PrintReport, LogReport, Evaluator\n",
    "from chainer.training.triggers import EarlyStoppingTrigger, MinValueTrigger\n",
    "from chainer import serializers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from scipy.stats import spearmanr\n",
    "from pylab import rcParams\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'VIS_CAT'\n",
    "exclude = [\"DateTime\",'VIS','VIS_CAT','FG','PRCP_P24HR']\n",
    "features = [val for val in DATA.columns if val not in exclude]\n",
    "\n",
    "# 特徴量を割り算で作成\n",
    "cutoff_r = 0.5\n",
    "new_added_col = []\n",
    "for i in range(0, len(features)-1):\n",
    "    for j in range(i+1, len(features)):\n",
    "        first_col_name = features[i]\n",
    "        second_col_name = features[j]\n",
    "        r = spearmanr(DATA[first_col_name], DATA[second_col_name]).correlation        \n",
    "        if abs(r) > cutoff_r:\n",
    "            new_colname = first_col_name + \"_div_\" + second_col_name\n",
    "            DATA[new_colname] = DATA[first_col_name] / (DATA[second_col_name] + 0.001)\n",
    "            new_added_col.append(new_colname)\n",
    "features = features + new_added_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SMOTEする\n",
    "# VIS 5000m以上を減らし、VIS 5000m未満を増やす\n",
    "def Over_Sampling( data ):\n",
    "    data[\"FLAG\"] = Sampling_Flag( data.VIS_CAT )\n",
    "\n",
    "    target = 'FLAG'\n",
    "    exclude = ['FLAG','DateTime']\n",
    "    features = [val for val in DATA.columns if val not in exclude]\n",
    "\n",
    "    y = np.array( data[target] )\n",
    "    X = np.array( data[features] )\n",
    "\n",
    "    count = int( y[y==0].shape[0] / 2 )\n",
    "    sm = SMOTE(ratio={1:count}, random_state=443)\n",
    "    X_sm, y_sm = sm.fit_sample(X,y)\n",
    "\n",
    "    data_s = pd.DataFrame( X_sm, columns=features )\n",
    "    data_s.FG = data_s.FG.astype(np.int64)\n",
    "    data_s.VIS_CAT = data_s.VIS_CAT.astype(np.int64)\n",
    "    return data_s\n",
    "\n",
    "def Sampling_Flag(data):\n",
    "    flag = np.full( data.shape[0], 0 )\n",
    "    flag[ data > 0 ] = 1\n",
    "    return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Chain):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.l1 = L.Linear(500)\n",
    "            self.l2 = L.Linear(1000)\n",
    "            self.l3 = L.Linear(500)\n",
    "            self.l4 = L.Linear(5)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        h = self.l1(x)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, ratio=0.5)\n",
    "\n",
    "        h = self.l2(h)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, ratio=0.5)\n",
    "\n",
    "        h = self.l3(h)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, ratio=0.5)\n",
    "\n",
    "        h = self.l4(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 最もLOSSが低い（ACCURACYが高い）モデルを保存しておく\n",
    "# by @koreyou\n",
    "# https://qiita.com/koreyou/items/1982c2ac5bf0191fbe6b\n",
    "\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "import chainer\n",
    "from chainer.training import extension\n",
    "\n",
    "def _snapshot_object(trainer, target, filename, savefun):\n",
    "    fd, tmppath = tempfile.mkstemp()\n",
    "    try:\n",
    "        savefun(tmppath, target)\n",
    "    except Exception:\n",
    "        os.close(fd)\n",
    "        os.remove(tmppath)\n",
    "        raise\n",
    "    os.close(fd)\n",
    "    shutil.move(tmppath, filename)\n",
    "\n",
    "\n",
    "class SaveRestore(chainer.training.extension.Extension):\n",
    "\n",
    "    \"\"\"Trainer extension to save a snapshot and restore it at the end of\n",
    "    training.\n",
    "\n",
    "    Typical usage is:\n",
    "\n",
    "    .. code-block:: python\n",
    "\n",
    "        trainer.extend(\n",
    "            SaveRestore(),\n",
    "            trigger=chainer.training.triggers.MinValueTrigger('validation/main/loss'))\n",
    "\n",
    "    which save will save snapshots and apply (pseudo-) early stopping by\n",
    "    loading the snapshot with the best validation loss.\n",
    "\n",
    "    Args:\n",
    "        filename (str): Name of the file into which the object is serialized.\n",
    "            It can be a format string, where the trainer object is passed to\n",
    "            the :meth:`str.format` method. For example,\n",
    "            ``'snapshot_{.updater.iteration}'`` is converted to\n",
    "            ``'snapshot_10000'`` at the 10,000th iteration.\n",
    "            Or you can give name without formatter, which will overwrite the\n",
    "            saved object on each call, thus only keeping the best model on\n",
    "            the disk.\n",
    "            Or you can give None, in which case the object is saved to\n",
    "            a temporaly path and deleted at the end of the training.\n",
    "        savefun: Function to save the object. It takes two arguments: the\n",
    "            output file path and the object to serialize.\n",
    "        loadfun: Function to load the object. It takes two arguments: the\n",
    "            file path and the object to deserialize.\n",
    "    \"\"\"\n",
    "    priority = -100\n",
    "\n",
    "    def __init__(self, filename='snapshot_iter_{.updater.iteration}',\n",
    "                 savefun=chainer.serializers.npz.save_npz,\n",
    "                 loadfun=chainer.serializers.npz.load_npz):\n",
    "        super(SaveRestore, self).__init__()\n",
    "        self._savefun = savefun\n",
    "        self._loadfun = loadfun\n",
    "        self._saved_iteration = None\n",
    "        self._keep_snapshot = filename is not None\n",
    "        self._filename = filename or 'saverestore' + str(hash(random.random()))\n",
    "\n",
    "    def __call__(self, trainer):\n",
    "        fn = self._filename.format(trainer)\n",
    "        self._saved_path = os.path.join(trainer.out, fn)\n",
    "        if not os.path.exists(trainer.out):\n",
    "            os.makedirs(trainer.out)        \n",
    "        _snapshot_object(trainer, trainer, self._saved_path, self._savefun)\n",
    "        self._saved_iteration = trainer.updater.iteration\n",
    "        self._trainer = trainer  # get referencee to trainer\n",
    "\n",
    "    def finalize(self):\n",
    "        if self._saved_iteration is not None:\n",
    "            print('Loading model from %d iteration' % self._saved_iteration)\n",
    "            self._loadfun(self._saved_path, self._trainer)\n",
    "        else:\n",
    "            print('Warning: SaveRestore was never triggered')\n",
    "        if not self._keep_snapshot and os.path.exists(self._saved_path):\n",
    "            os.remove(self._saved_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOSS計算時に重み付けをする\n",
    "def Loss_Func(x, t):\n",
    "    cw = np.array([1, 2, 2, 3, 3]).astype(np.float32)\n",
    "    return F.softmax_cross_entropy(x, t, class_weight=cw)\n",
    "\n",
    "## カテゴリー評価\n",
    "def Category_Evaluation(obs_cat, fcst_cat):\n",
    "    matrix = confusion_matrix(y_true=obs_cat, y_pred=fcst_cat)\n",
    "    print( matrix )\n",
    "    print( \"Accuracy : \", accuracy_score( obs_cat, fcst_cat ) )\n",
    "    print( \"F1 average : \", f1_score( obs_cat, fcst_cat, average='macro' ) )\n",
    "    print( \"Weighted F1 : \", Weighted_F1(matrix) )\n",
    "    print( \"ETS 800m : \", ETS(obs_cat, fcst_cat, 4) )\n",
    "    print( \"BI 800m : \", BI(obs_cat, fcst_cat, 4) )\n",
    "    print( \"ETS 1600m : \", ETS(obs_cat, fcst_cat, 3) )\n",
    "    print( \"BI 1600m : \", BI(obs_cat, fcst_cat, 3) )\n",
    "\n",
    "def OneCat_Evaluation(obs_cat, fcst_cat):\n",
    "    matrix = confusion_matrix(y_true=obs_cat, y_pred=fcst_cat)\n",
    "    print( matrix )\n",
    "    print( \"Accuracy : \", accuracy_score( obs_cat, fcst_cat ) )\n",
    "    print( \"ETS 1600m : \", ETS(obs_cat, fcst_cat, 1) )\n",
    "    print( \"BI 1600m : \", BI(obs_cat, fcst_cat, 1) )\n",
    "\n",
    "## Equitable Threat Score\n",
    "def ETS(obs_cat, fcst_cat, rank):\n",
    "    obs_onoff = np.full( len(obs_cat), 0 )\n",
    "    obs_onoff[ obs_cat >= rank ] = 1\n",
    "    fcst_onoff = np.full( len(fcst_cat), 0 )\n",
    "    fcst_onoff[ fcst_cat >= rank ] = 1\n",
    "\n",
    "    m = confusion_matrix(y_true=obs_onoff, y_pred=fcst_onoff)\n",
    "    Pc = len(obs_onoff[ obs_onoff == 1 ]) / len(obs_onoff)\n",
    "    Sf = Pc * ( m[1,1] + m[0,1] ) # ランダム的中率\n",
    "    ets = ( m[1,1] - Sf ) / ( m[0,1] + m[1,0] + m[1,1] - Sf )\n",
    "    return ets\n",
    "\n",
    "## バイアススコア\n",
    "def BI(obs_cat, fcst_cat, rank):\n",
    "    obs_onoff = np.full( len(obs_cat), 0 )\n",
    "    obs_onoff[ obs_cat >= rank ] = 1\n",
    "    fcst_onoff = np.full( len(fcst_cat), 0 )\n",
    "    fcst_onoff[ fcst_cat >= rank ] = 1\n",
    "\n",
    "    m = confusion_matrix(y_true=obs_onoff, y_pred=fcst_onoff)\n",
    "    bi = m[:,1].sum() / m[1,:].sum()\n",
    "    return bi\n",
    "\n",
    "## 各カテゴリーの総数の逆数で重み付け\n",
    "# 低い視程カテゴリーの正解に重みをつけたい\n",
    "def Weighted_F1(m):\n",
    "    F1_score = []\n",
    "    total = 0\n",
    "    for i in range( len(m) ):\n",
    "        if m[:,i].sum() == 0:\n",
    "            precision = 0\n",
    "        else:\n",
    "            precision = m[i,i] / m[:,i].sum()\n",
    "\n",
    "        if m[i,:].sum() == 0:\n",
    "            recall = 0\n",
    "        else:\n",
    "            recall = m[i,i] / m[i,:].sum()\n",
    "\n",
    "        if precision + recall == 0:\n",
    "            f1 = 0\n",
    "        else:\n",
    "            f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "        if m[i,:].sum() == 0:\n",
    "            F1_score.append( 0 )\n",
    "        else:\n",
    "            F1_score.append( f1 / m[i,:].sum() )\n",
    "            total += 1 / m[i,:].sum()\n",
    "\n",
    "    fin_score = sum( F1_score ) / total\n",
    "    return fin_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 事前学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_learn = 17429\n",
    "\n",
    "# DATA_O = DATA[0:pre_learn].reset_index(drop=True)\n",
    "# DATA_S = Over_Sampling( DATA_O )\n",
    "# Y = DATA_S[target]\n",
    "# X = DATA_S[features]\n",
    "Y = DATA[target][0:pre_learn]\n",
    "X = DATA[features][0:pre_learn]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform( X )\n",
    "X_train, X_dev, Y_train, Y_dev = train_test_split(X, Y, test_size=0.3, random_state=443)\n",
    "\n",
    "## Chainer用の変換\n",
    "Y_train = Y_train.values\n",
    "Y_dev = Y_dev.values\n",
    "\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_dev = X_dev.astype(np.float32)\n",
    "\n",
    "Y_train = Y_train.astype(np.int32)\n",
    "Y_dev = Y_dev.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   main/loss   dev/main/loss\n",
      "\u001b[J12          1.14117     0.823959       \n",
      "\u001b[J24          0.728925    0.720203       \n",
      "\u001b[J36          0.667643    0.688414       \n",
      "\u001b[J48          0.639586    0.662609       \n",
      "\u001b[J60          0.61829     0.651228       \n",
      "\u001b[J72          0.60801     0.63971        \n",
      "\u001b[J84          0.590293    0.634516       \n",
      "\u001b[J96          0.585025    0.621749       \n",
      "\u001b[J108         0.579472    0.618706       \n",
      "\u001b[J120         0.56449     0.618385       \n",
      "\u001b[J132         0.55187     0.602066       \n",
      "\u001b[J143         0.542608    0.600708       \n",
      "\u001b[J155         0.540417    0.605403       \n",
      "\u001b[J167         0.534434    0.591902       \n",
      "\u001b[J179         0.525342    0.585495       \n",
      "\u001b[J191         0.516156    0.581077       \n",
      "\u001b[J203         0.516885    0.585973       \n",
      "\u001b[J215         0.497711    0.573058       \n",
      "\u001b[J227         0.502077    0.572185       \n",
      "\u001b[J239         0.476261    0.565754       \n",
      "\u001b[J251         0.481949    0.562809       \n",
      "\u001b[J263         0.462793    0.563689       \n",
      "\u001b[J275         0.460252    0.559314       \n",
      "\u001b[J286         0.457145    0.55705        \n",
      "\u001b[J298         0.450354    0.554317       \n",
      "\u001b[J310         0.444766    0.553779       \n",
      "\u001b[J322         0.439606    0.550101       \n",
      "\u001b[J334         0.427501    0.549225       \n",
      "\u001b[J346         0.4248      0.542849       \n",
      "\u001b[J358         0.417454    0.545902       \n",
      "\u001b[J370         0.403272    0.542155       \n",
      "\u001b[J382         0.391254    0.544093       \n",
      "\u001b[J394         0.391297    0.545886       \n",
      "\u001b[J406         0.391252    0.54056        \n",
      "\u001b[J417         0.384841    0.536982       \n",
      "\u001b[J429         0.375222    0.543333       \n",
      "\u001b[J441         0.366064    0.548705       \n",
      "\u001b[J453         0.356287    0.555203       \n",
      "\u001b[J465         0.363468    0.560684       \n",
      "\u001b[J477         0.350213    0.551741       \n",
      "\u001b[J489         0.335397    0.563236       \n",
      "\u001b[J501         0.331043    0.56344        \n",
      "\u001b[J513         0.336402    0.571642       \n",
      "\u001b[J525         0.335253    0.566065       \n",
      "\u001b[J537         0.317501    0.566975       \n",
      "\u001b[J549         0.316215    0.558253       \n",
      "\u001b[J560         0.30439     0.57176        \n",
      "\u001b[J572         0.302581    0.580512       \n",
      "\u001b[J584         0.296525    0.577701       \n",
      "\u001b[J596         0.293573    0.568806       \n",
      "\u001b[J608         0.287429    0.584106       \n",
      "\u001b[J620         0.282535    0.598018       \n",
      "\u001b[J632         0.268619    0.596901       \n",
      "\u001b[J644         0.27898     0.583717       \n",
      "\u001b[J656         0.282697    0.581903       \n",
      "\u001b[J668         0.273372    0.601751       \n",
      "\u001b[J680         0.257116    0.599463       \n",
      "\u001b[J692         0.26202     0.604148       \n",
      "\u001b[J703         0.260667    0.588325       \n",
      "\u001b[J715         0.252051    0.598328       \n",
      "\u001b[J727         0.244169    0.600016       \n",
      "\u001b[J739         0.250367    0.615713       \n",
      "\u001b[J751         0.248194    0.60384        \n",
      "\u001b[J763         0.244638    0.606981       \n",
      "\u001b[J775         0.23607     0.62634        \n",
      "\u001b[J787         0.235212    0.621021       \n",
      "\u001b[J799         0.239967    0.616669       \n",
      "\u001b[J811         0.232558    0.612679       \n",
      "\u001b[J823         0.225991    0.623642       \n",
      "\u001b[J834         0.230656    0.62527        \n",
      "\u001b[J846         0.223217    0.612115       \n",
      "\u001b[J858         0.219849    0.625663       \n",
      "\u001b[J870         0.204       0.645415       \n",
      "\u001b[J882         0.210139    0.65841        \n",
      "\u001b[J894         0.206209    0.655913       \n",
      "\u001b[J906         0.19775     0.661116       \n",
      "\u001b[J918         0.201558    0.678669       \n",
      "\u001b[J930         0.208377    0.665296       \n",
      "\u001b[J942         0.195034    0.649228       \n",
      "\u001b[J954         0.199078    0.655593       \n",
      "\u001b[J966         0.188975    0.653752       \n",
      "\u001b[J977         0.187602    0.676455       \n",
      "\u001b[J989         0.190269    0.666197       \n",
      "\u001b[J1001        0.185161    0.643748       \n",
      "\u001b[J1013        0.185327    0.663346       \n",
      "\u001b[J1025        0.177221    0.676371       \n",
      "\u001b[J1037        0.178548    0.68762        \n",
      "\u001b[J1049        0.16379     0.69186        \n",
      "\u001b[J1061        0.18453     0.683553       \n",
      "\u001b[J1073        0.168473    0.693902       \n",
      "\u001b[J1085        0.1675      0.71197        \n",
      "\u001b[J1097        0.17009     0.715674       \n",
      "\u001b[J1109        0.172732    0.699137       \n",
      "\u001b[J1120        0.162184    0.717301       \n",
      "\u001b[J1132        0.173141    0.735758       \n",
      "\u001b[J1144        0.162548    0.722358       \n",
      "\u001b[J1156        0.158652    0.715718       \n",
      "\u001b[J1168        0.152136    0.709964       \n",
      "\u001b[J1180        0.15032     0.736349       \n",
      "\u001b[J1192        0.15424     0.718711       \n",
      "\u001b[J1204        0.152545    0.718323       \n",
      "\u001b[J1216        0.146407    0.74599        \n",
      "\u001b[J1228        0.144745    0.752216       \n",
      "\u001b[J1240        0.149386    0.738666       \n",
      "\u001b[J1251        0.147512    0.734081       \n",
      "\u001b[J1263        0.147663    0.755655       \n",
      "\u001b[J1275        0.147429    0.767651       \n",
      "\u001b[J1287        0.143937    0.755991       \n",
      "\u001b[J1299        0.13602     0.75429        \n",
      "\u001b[J1311        0.147744    0.771115       \n",
      "\u001b[J1323        0.133349    0.793223       \n",
      "\u001b[J1335        0.143559    0.76487        \n",
      "\u001b[J1347        0.135176    0.763629       \n",
      "\u001b[J1359        0.136164    0.784962       \n",
      "\u001b[J1371        0.125796    0.778551       \n",
      "\u001b[J1383        0.124495    0.825361       \n",
      "\u001b[J1394        0.134595    0.785554       \n",
      "\u001b[J1406        0.138437    0.805793       \n",
      "\u001b[J1418        0.126375    0.782101       \n",
      "\u001b[J1430        0.118623    0.803939       \n",
      "\u001b[J1442        0.120794    0.811322       \n",
      "\u001b[J1454        0.130579    0.820315       \n",
      "\u001b[J1466        0.12726     0.790729       \n",
      "\u001b[J1478        0.121015    0.799793       \n",
      "\u001b[J1490        0.121268    0.81048        \n",
      "\u001b[J1502        0.118625    0.82876        \n",
      "\u001b[J1514        0.119373    0.825656       \n",
      "\u001b[J1525        0.116418    0.822098       \n",
      "\u001b[J1537        0.126322    0.82809        \n",
      "\u001b[J1549        0.122178    0.861261       \n",
      "\u001b[J1561        0.117345    0.800944       \n",
      "\u001b[J1573        0.117075    0.835995       \n",
      "\u001b[J1585        0.114264    0.802095       \n",
      "\u001b[J1597        0.114221    0.831436       \n",
      "\u001b[J1609        0.108816    0.844018       \n",
      "\u001b[J1621        0.10745     0.84193        \n",
      "\u001b[J1633        0.110143    0.847933       \n",
      "\u001b[J1645        0.111163    0.856257       \n",
      "\u001b[J1657        0.108288    0.866877       \n",
      "Loading model from 417 iteration\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "classifier = L.Classifier( model, lossfun=Loss_Func )\n",
    "optimizer = Adam()\n",
    "optimizer.setup(classifier)\n",
    "\n",
    "train_dataset = TupleDataset(X_train, Y_train)\n",
    "dev_dataset = TupleDataset(X_dev, Y_dev)\n",
    "# test_dataset = TupleDataset(X_test, Y_test)\n",
    "\n",
    "train_iterator = SerialIterator(train_dataset, batch_size=1024, repeat=True)\n",
    "dev_iterator = SerialIterator(dev_dataset, batch_size=1024, shuffle=False, repeat=False)\n",
    "# test_iterator = SerialIterator(test_dataset, batch_size=1024, shuffle=False, repeat=False)\n",
    "\n",
    "updater = StandardUpdater(train_iterator, optimizer, loss_func=classifier)\n",
    "stop_trigger = EarlyStoppingTrigger(check_trigger=(10, 'epoch'), monitor='dev/main/loss',\\\n",
    "                                    patients=10, max_trigger=(600, 'epoch'))\n",
    "\n",
    "trainer = Trainer(updater, stop_trigger)\n",
    "trainer.extend(Evaluator(dev_iterator, classifier), trigger=(1, 'epoch'), name=\"dev\")\n",
    "# trainer.extend(Evaluator(test_iterator, classifier), trigger=(1, 'epoch'), name=\"test\")\n",
    "trainer.extend(PrintReport(['iteration', \"main/loss\", \"dev/main/loss\"]))\n",
    "trainer.extend(SaveRestore(), trigger=MinValueTrigger('dev/main/loss', trigger=(1, 'epoch')))\n",
    "\n",
    "logreport = LogReport(trigger=(1, 'epoch'))\n",
    "trainer.extend(logreport)\n",
    "trainer.run()\n",
    "\n",
    "serializers.save_npz('DNN_CLF_CAT4.npz', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dev/main/accuracy</th>\n",
       "      <th>dev/main/loss</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>epoch</th>\n",
       "      <th>iteration</th>\n",
       "      <th>main/accuracy</th>\n",
       "      <th>main/loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.877845</td>\n",
       "      <td>0.542155</td>\n",
       "      <td>58.093356</td>\n",
       "      <td>31</td>\n",
       "      <td>370</td>\n",
       "      <td>0.899984</td>\n",
       "      <td>0.403272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.876967</td>\n",
       "      <td>0.544093</td>\n",
       "      <td>59.913507</td>\n",
       "      <td>32</td>\n",
       "      <td>382</td>\n",
       "      <td>0.901693</td>\n",
       "      <td>0.391254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.876804</td>\n",
       "      <td>0.545886</td>\n",
       "      <td>61.187320</td>\n",
       "      <td>33</td>\n",
       "      <td>394</td>\n",
       "      <td>0.903727</td>\n",
       "      <td>0.391297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.872084</td>\n",
       "      <td>0.540560</td>\n",
       "      <td>62.469840</td>\n",
       "      <td>34</td>\n",
       "      <td>406</td>\n",
       "      <td>0.902588</td>\n",
       "      <td>0.391252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.880414</td>\n",
       "      <td>0.536982</td>\n",
       "      <td>64.265427</td>\n",
       "      <td>35</td>\n",
       "      <td>417</td>\n",
       "      <td>0.906161</td>\n",
       "      <td>0.384841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dev/main/accuracy  dev/main/loss  elapsed_time  epoch  iteration  \\\n",
       "30           0.877845       0.542155     58.093356     31        370   \n",
       "31           0.876967       0.544093     59.913507     32        382   \n",
       "32           0.876804       0.545886     61.187320     33        394   \n",
       "33           0.872084       0.540560     62.469840     34        406   \n",
       "34           0.880414       0.536982     64.265427     35        417   \n",
       "\n",
       "    main/accuracy  main/loss  \n",
       "30       0.899984   0.403272  \n",
       "31       0.901693   0.391254  \n",
       "32       0.903727   0.391297  \n",
       "33       0.902588   0.391252  \n",
       "34       0.906161   0.384841  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a18e3ff60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rcParams['figure.figsize'] = 10,7\n",
    "log_df = pd.DataFrame(logreport.log)\n",
    "pd.DataFrame(log_df[[\"main/loss\", \"dev/main/loss\"]].values, columns=[\"main/loss\", \"dev/main/loss\"], index=log_df[\"iteration\"]).plot()\n",
    "log_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.95      0.95      4583\n",
      "          1       0.34      0.36      0.35       330\n",
      "          2       0.39      0.38      0.38       232\n",
      "          3       0.29      0.40      0.34        42\n",
      "          4       0.42      0.67      0.51        42\n",
      "\n",
      "avg / total       0.88      0.88      0.88      5229\n",
      "\n",
      "[[4342  159   64    6   12]\n",
      " [ 123  120   66    9   12]\n",
      " [  52   63   88   20    9]\n",
      " [   8    4    7   17    6]\n",
      " [   5    2    1    6   28]]\n",
      "Accuracy :  0.8787531076687704\n",
      "F1 average :  0.5089895276961298\n",
      "Weighted F1 :  0.4216295558368663\n",
      "ETS 800m :  0.34130272023958075\n",
      "BI 800m :  1.5952380952380953\n",
      "ETS 1600m :  0.3666327514190854\n",
      "BI 1600m :  1.4880952380952381\n"
     ]
    }
   ],
   "source": [
    "with configuration.using_config('train', False):\n",
    "    y_calc = model(X_dev)\n",
    "# y_arr = np.array([i.data for i in y_calc])\n",
    "# y_pred = np.argmax(y_arr, axis=1)\n",
    "y_pred = np.argmax(y_calc.data, axis=1)\n",
    "print(classification_report(Y_dev, y_pred))\n",
    "# pd.crosstab(Y_dev, y_pred)\n",
    "Category_Evaluation(Y_dev, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOSS計算時に重み付けをする\n",
    "def Loss_Func(x, t):\n",
    "    cw = np.array([1, 2, 2, 3, 3]).astype(np.float32)\n",
    "    return F.softmax_cross_entropy(x, t, class_weight=cw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop 0 times of 23\n",
      "iteration   main/loss   dev/main/loss  test/main/loss\n",
      "\u001b[J21          0.214618    0.162488       0.163751        \n",
      "Loading model from 42 iteration\n",
      "loop 1 times of 23\n",
      "iteration   main/loss   dev/main/loss  test/main/loss\n",
      "\u001b[J21          0.331555    0.304727       0.262609        \n",
      "Loading model from 42 iteration\n",
      "loop 2 times of 23\n",
      "iteration   main/loss   dev/main/loss  test/main/loss\n",
      "\u001b[J21          0.457332    0.293714       0.317464        \n",
      "Loading model from 42 iteration\n",
      "loop 3 times of 23\n",
      "iteration   main/loss   dev/main/loss  test/main/loss\n",
      "\u001b[J21          0.444097    0.380642       0.387104        \n",
      "Loading model from 42 iteration\n",
      "loop 4 times of 23\n",
      "iteration   main/loss   dev/main/loss  test/main/loss\n",
      "\u001b[J21          0.455015    0.295634       0.319222        \n",
      "Loading model from 42 iteration\n",
      "loop 5 times of 23\n",
      "iteration   main/loss   dev/main/loss  test/main/loss\n",
      "\u001b[J21          0.767442    0.649037       0.635268        \n",
      "Loading model from 21 iteration\n",
      "loop 6 times of 23\n",
      "iteration   main/loss   dev/main/loss  test/main/loss\n",
      "\u001b[J21          0.728821    0.783959       0.647421        \n",
      "Loading model from 42 iteration\n",
      "loop 7 times of 23\n",
      "iteration   main/loss   dev/main/loss  test/main/loss\n",
      "\u001b[J21          0.962031    0.678998       0.77618         \n",
      "Loading model from 42 iteration\n",
      "loop 8 times of 23\n",
      "iteration   main/loss   dev/main/loss  test/main/loss\n",
      "\u001b[J21          1.38306     1.25917        1.23875         \n",
      "Loading model from 42 iteration\n",
      "loop 9 times of 23\n",
      "iteration   main/loss   dev/main/loss  test/main/loss\n",
      "\u001b[J21          0.541077    0.588686       0.517374        \n",
      "Loading model from 42 iteration\n",
      "loop 10 times of 23\n",
      "iteration   main/loss   dev/main/loss  test/main/loss\n",
      "\u001b[J21          0.847208    0.654401       0.665294        \n",
      "Loading model from 21 iteration\n",
      "loop 11 times of 23\n",
      "iteration   main/loss   dev/main/loss  test/main/loss\n",
      "\u001b[J21          0.421182    0.307344       0.334421        \n",
      "Loading model from 42 iteration\n",
      "loop 12 times of 23\n",
      "iteration   main/loss   dev/main/loss  test/main/loss\n",
      "\u001b[J21          0.239777    0.123154       0.175355        \n",
      "Loading model from 42 iteration\n",
      "loop 13 times of 23\n",
      "iteration   main/loss   dev/main/loss  test/main/loss\n",
      "\u001b[J21          0.456884    0.374026       0.368699        \n",
      "Loading model from 42 iteration\n",
      "loop 14 times of 23\n",
      "iteration   main/loss   dev/main/loss  test/main/loss\n",
      "\u001b[J21          0.314679    0.247287       0.251428        \n",
      "Loading model from 42 iteration\n",
      "loop 15 times of 23\n",
      "iteration   main/loss   dev/main/loss  test/main/loss\n",
      "\u001b[J21          0.543362    0.365938       0.411662        \n",
      "Loading model from 42 iteration\n",
      "loop 16 times of 23\n",
      "iteration   main/loss   dev/main/loss  test/main/loss\n",
      "\u001b[J21          0.693891    0.464192       0.585223        \n",
      "Loading model from 42 iteration\n",
      "loop 17 times of 23\n",
      "iteration   main/loss   dev/main/loss  test/main/loss\n",
      "\u001b[J21          0.598607    0.611261       0.600186        \n",
      "Loading model from 42 iteration\n",
      "loop 18 times of 23\n",
      "iteration   main/loss   dev/main/loss  test/main/loss\n",
      "\u001b[J21          0.8902      0.82453        0.801045        \n",
      "Loading model from 42 iteration\n",
      "loop 19 times of 23\n",
      "iteration   main/loss   dev/main/loss  test/main/loss\n",
      "\u001b[J21          0.893531    0.858388       0.849071        \n",
      "Loading model from 42 iteration\n",
      "loop 20 times of 23\n",
      "iteration   main/loss   dev/main/loss  test/main/loss\n",
      "\u001b[J21          0.754119    0.757323       0.663421        \n",
      "Loading model from 42 iteration\n",
      "loop 21 times of 23\n",
      "iteration   main/loss   dev/main/loss  test/main/loss\n",
      "\u001b[J21          1.23708     0.942864       0.99266         \n",
      "Loading model from 21 iteration\n",
      "loop 22 times of 23\n",
      "iteration   main/loss   dev/main/loss  test/main/loss\n",
      "\u001b[J21          0.338505    0.242185       0.265584        \n",
      "Loading model from 42 iteration\n",
      "loop 23 times of 23\n"
     ]
    }
   ],
   "source": [
    "### オンライン学習\n",
    "## ループの設定\n",
    "learn_hours = 30 * 24\n",
    "one_step = 30 * 24\n",
    "all_rows = DATA.shape[0]\n",
    "repeat = int( (all_rows - pre_learn) / one_step )\n",
    "\n",
    "fg_fcst = np.zeros( pre_learn )\n",
    "fg_obs = np.zeros( pre_learn )\n",
    "\n",
    "## 学習と予測ループ\n",
    "for i in range( repeat + 1 ):\n",
    "    print( \"loop {} times of {}\".format(i,repeat) )\n",
    "    \n",
    "    ## ループのパラメータ\n",
    "    fcst_start = pre_learn + i * one_step\n",
    "    fcst_end = fcst_start + one_step\n",
    "    if i == repeat:\n",
    "        fcst_end = all_rows\n",
    "    learn_end = fcst_end\n",
    "    learn_start = fcst_end - learn_hours\n",
    "#     print( fcst_start, fcst_end, learn_start, learn_end )\n",
    "    \n",
    "    ## 予測\n",
    "    Y_test = DATA[target][fcst_start:fcst_end]\n",
    "    X_test = DATA[features][fcst_start:fcst_end]\n",
    "    X_test = scaler.transform( X_test )\n",
    "\n",
    "    Y_test = Y_test.values\n",
    "    X_test = X_test.astype(np.float32)\n",
    "    Y_test = Y_test.astype(np.int32)\n",
    "\n",
    "    with configuration.using_config('train', False):\n",
    "        y_calc = model(X_test)\n",
    "    # y_arr = np.array([i.data for i in y_calc])\n",
    "    # y_pred = np.argmax(y_arr, axis=1)\n",
    "    y_pred = np.argmax(y_calc.data, axis=1)\n",
    "\n",
    "    fg_fcst = np.r_[fg_fcst, y_pred]\n",
    "    fg_obs = np.r_[fg_obs, Y_test]\n",
    "    \n",
    "    if i == repeat:\n",
    "        break\n",
    "    \n",
    "    ## 学習\n",
    "#     DATA_O = DATA[learn_start:learn_end].reset_index(drop=True)\n",
    "#     DATA_S = Over_Sampling( DATA_O )\n",
    "#     Y = DATA_S[target]\n",
    "#     X = DATA_S[features]\n",
    "    Y = DATA[target][learn_start:learn_end]\n",
    "    X = DATA[features][learn_start:learn_end]\n",
    "\n",
    "    scaler.partial_fit( X )\n",
    "    X = scaler.transform( X )\n",
    "    X_train, X_dev, Y_train, Y_dev = train_test_split(X, Y, test_size=0.3, random_state=443)\n",
    "#     X_train = X\n",
    "#     Y_train = Y\n",
    "\n",
    "    ## Chainer用の変換\n",
    "    Y_train = Y_train.values\n",
    "    Y_dev = Y_dev.values\n",
    "\n",
    "    X_train = X_train.astype(np.float32)\n",
    "    X_dev = X_dev.astype(np.float32)\n",
    "\n",
    "    Y_train = Y_train.astype(np.int32)\n",
    "    Y_dev = Y_dev.astype(np.int32)\n",
    "\n",
    "    ## Chainerを走らせる\n",
    "    model = Model()\n",
    "    if i == 0:\n",
    "        serializers.load_npz(\"DNN_CLF_CAT4.npz\", model)\n",
    "    else:\n",
    "        serializers.load_npz(\"DNN_CLF_CAT4_online.npz\", model)\n",
    "    classifier = L.Classifier( model, lossfun=Loss_Func )\n",
    "#     optimizer = Adam()\n",
    "    optimizer = SGD()\n",
    "    optimizer.setup(classifier)\n",
    "\n",
    "    train_dataset = TupleDataset(X_train, Y_train)\n",
    "    dev_dataset = TupleDataset(X_dev, Y_dev)\n",
    "    test_dataset = TupleDataset(X_test, Y_test)\n",
    "\n",
    "    train_iterator = SerialIterator(train_dataset, batch_size=24, repeat=True)\n",
    "    dev_iterator = SerialIterator(dev_dataset, batch_size=24, shuffle=False, repeat=False)\n",
    "    test_iterator = SerialIterator(test_dataset, batch_size=24, shuffle=False, repeat=False)\n",
    "\n",
    "    updater = StandardUpdater(train_iterator, optimizer, loss_func=classifier)\n",
    "    stop_trigger = EarlyStoppingTrigger(check_trigger=(1, 'epoch'), monitor='dev/main/loss',\\\n",
    "                                        patients=1, max_trigger=(2, 'epoch'))\n",
    "\n",
    "    trainer = Trainer(updater, stop_trigger)\n",
    "    trainer.extend(Evaluator(dev_iterator, classifier), trigger=(1, 'epoch'), name=\"dev\")\n",
    "    trainer.extend(Evaluator(test_iterator, classifier), trigger=(1, 'epoch'), name=\"test\")\n",
    "    trainer.extend(PrintReport(['iteration', \"main/loss\", \"dev/main/loss\", \"test/main/loss\"]))\n",
    "    trainer.extend(SaveRestore(), trigger=MinValueTrigger('dev/main/loss', trigger=(1, 'epoch')))\n",
    "\n",
    "    logreport = LogReport(trigger=(1, 'epoch'))\n",
    "    trainer.extend(logreport)\n",
    "    trainer.run()\n",
    "\n",
    "    serializers.save_npz('DNN_CLF_CAT4_online.npz', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      0.96      0.95      7850\n",
      "        1.0       0.21      0.08      0.12       445\n",
      "        2.0       0.31      0.38      0.34       343\n",
      "        3.0       0.02      0.02      0.02        65\n",
      "        4.0       0.12      0.29      0.17        48\n",
      "\n",
      "avg / total       0.87      0.88      0.87      8751\n",
      "\n",
      "[[7540   77  171   20   42]\n",
      " [ 263   37  101   17   27]\n",
      " [ 135   52  131    7   18]\n",
      " [  30    6   15    1   13]\n",
      " [  20    5    7    2   14]]\n",
      "Accuracy :  0.8825277111187293\n",
      "F1 average :  0.32059079304539767\n",
      "Weighted F1 :  0.12669335001735518\n",
      "ETS 800m :  0.09075302634149972\n",
      "BI 800m :  2.375\n",
      "ETS 1600m :  0.11541384690307413\n",
      "BI 1600m :  1.424778761061947\n"
     ]
    }
   ],
   "source": [
    "# 2016年：17429 - 26180\n",
    "# 2017年：26181 - \n",
    "print(classification_report(fg_obs[17429:26180], fg_fcst[17429:26180]))\n",
    "# pd.crosstab(fg_obs[17429:26180], fg_fcst[17429:26180])\n",
    "Category_Evaluation(fg_obs[17429:26180], fg_fcst[17429:26180])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      0.96      0.95      7302\n",
      "        1.0       0.29      0.14      0.19       376\n",
      "        2.0       0.28      0.19      0.23       360\n",
      "        3.0       0.03      0.02      0.02        55\n",
      "        4.0       0.09      0.20      0.13        44\n",
      "\n",
      "avg / total       0.86      0.88      0.87      8137\n",
      "\n",
      "[[7044   82  107   14   55]\n",
      " [ 249   54   54    7   12]\n",
      " [ 222   52   68    6   12]\n",
      " [  37    1    9    1    7]\n",
      " [  28    0    4    3    9]]\n",
      "Accuracy :  0.8818975052230552\n",
      "F1 average :  0.3032926473251629\n",
      "Weighted F1 :  0.09963756243895973\n",
      "ETS 800m :  0.06553818702960243\n",
      "BI 800m :  2.159090909090909\n",
      "ETS 1600m :  0.09076165838472927\n",
      "BI 1600m :  1.2727272727272727\n"
     ]
    }
   ],
   "source": [
    "# 2016年：17429 - 26180\n",
    "# 2017年：26181 - \n",
    "print(classification_report(fg_obs[26181:], fg_fcst[26181:]))\n",
    "# pd.crosstab(fg_obs[26181:], fg_fcst[26181:])\n",
    "Category_Evaluation(fg_obs[26181:], fg_fcst[26181:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### もっと深くしてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_D(Chain):\n",
    "    def __init__(self):\n",
    "        super(Model_D, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.l1 = L.Linear(500)\n",
    "            self.l2 = L.Linear(1000)\n",
    "            self.l3 = L.Linear(2000)\n",
    "            self.l4 = L.Linear(1000)\n",
    "            self.l5 = L.Linear(500)\n",
    "            self.l6 = L.Linear(5)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        h = self.l1(x)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, ratio=0.5)\n",
    "\n",
    "        h = self.l2(h)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, ratio=0.5)\n",
    "\n",
    "        h = self.l3(h)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, ratio=0.5)\n",
    "\n",
    "        h = self.l4(h)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, ratio=0.5)\n",
    "\n",
    "        h = self.l5(h)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, ratio=0.5)\n",
    "\n",
    "        h = self.l6(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOSS計算時に重み付けをする\n",
    "def Loss_Func(x, t):\n",
    "    cw = np.array([1, 2, 2, 3, 3]).astype(np.float32)\n",
    "    return F.softmax_cross_entropy(x, t, class_weight=cw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_learn = 17429\n",
    "\n",
    "DATA_O = DATA[0:pre_learn].reset_index(drop=True)\n",
    "DATA_S = Over_Sampling( DATA_O )\n",
    "Y = DATA_S[target]\n",
    "X = DATA_S[features]\n",
    "# Y = DATA[target][0:pre_learn]\n",
    "# X = DATA[features][0:pre_learn]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform( X )\n",
    "X_train, X_dev, Y_train, Y_dev = train_test_split(X, Y, test_size=0.3, random_state=443)\n",
    "\n",
    "## Chainer用の変換\n",
    "Y_train = Y_train.values\n",
    "Y_dev = Y_dev.values\n",
    "\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_dev = X_dev.astype(np.float32)\n",
    "\n",
    "Y_train = Y_train.astype(np.int32)\n",
    "Y_dev = Y_dev.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model_D()\n",
    "classifier = L.Classifier( model, lossfun=Loss_Func )\n",
    "optimizer = Adam()\n",
    "optimizer.setup(classifier)\n",
    "\n",
    "train_dataset = TupleDataset(X_train, Y_train)\n",
    "dev_dataset = TupleDataset(X_dev, Y_dev)\n",
    "# test_dataset = TupleDataset(X_test, Y_test)\n",
    "\n",
    "train_iterator = SerialIterator(train_dataset, batch_size=1024, repeat=True)\n",
    "dev_iterator = SerialIterator(dev_dataset, batch_size=1024, shuffle=False, repeat=False)\n",
    "# test_iterator = SerialIterator(test_dataset, batch_size=1024, shuffle=False, repeat=False)\n",
    "\n",
    "updater = StandardUpdater(train_iterator, optimizer, loss_func=classifier)\n",
    "stop_trigger = EarlyStoppingTrigger(check_trigger=(10, 'epoch'), monitor='dev/main/loss',\\\n",
    "                                    patients=10, max_trigger=(600, 'epoch'))\n",
    "\n",
    "trainer = Trainer(updater, stop_trigger)\n",
    "trainer.extend(Evaluator(dev_iterator, classifier), trigger=(1, 'epoch'), name=\"dev\")\n",
    "# trainer.extend(Evaluator(test_iterator, classifier), trigger=(1, 'epoch'), name=\"test\")\n",
    "trainer.extend(PrintReport(['iteration', \"main/loss\", \"dev/main/loss\"]))\n",
    "trainer.extend(SaveRestore(), trigger=MinValueTrigger('dev/main/loss', trigger=(1, 'epoch')))\n",
    "\n",
    "logreport = LogReport(trigger=(1, 'epoch'))\n",
    "trainer.extend(logreport)\n",
    "trainer.run()\n",
    "\n",
    "serializers.save_npz('DNN_CLF_CAT3.npz', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with configuration.using_config('train', False):\n",
    "    y_calc = model(X_dev)\n",
    "# y_arr = np.array([i.data for i in y_calc])\n",
    "# y_pred = np.argmax(y_arr, axis=1)\n",
    "y_pred = np.argmax(y_calc.data, axis=1)\n",
    "print(classification_report(Y_dev, y_pred))\n",
    "# pd.crosstab(Y_dev, y_pred)\n",
    "Category_Evaluation(Y_dev, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### オンライン学習\n",
    "## ループの設定\n",
    "learn_hours = 30 * 24\n",
    "one_step = 30 * 24\n",
    "all_rows = DATA.shape[0]\n",
    "repeat = int( (all_rows - pre_learn) / one_step )\n",
    "\n",
    "fg_fcst = np.zeros( pre_learn )\n",
    "fg_obs = np.zeros( pre_learn )\n",
    "\n",
    "## 学習と予測ループ\n",
    "for i in range( repeat + 1 ):\n",
    "    print( \"loop {} times of {}\".format(i,repeat) )\n",
    "    \n",
    "    ## ループのパラメータ\n",
    "    fcst_start = pre_learn + i * one_step\n",
    "    fcst_end = fcst_start + one_step\n",
    "    if i == repeat:\n",
    "        fcst_end = all_rows\n",
    "    learn_end = fcst_end\n",
    "    learn_start = fcst_end - learn_hours\n",
    "#     print( fcst_start, fcst_end, learn_start, learn_end )\n",
    "    \n",
    "    ## 予測\n",
    "    Y_test = DATA[target][fcst_start:fcst_end]\n",
    "    X_test = DATA[features][fcst_start:fcst_end]\n",
    "    X_test = scaler.transform( X_test )\n",
    "\n",
    "    Y_test = Y_test.values\n",
    "    X_test = X_test.astype(np.float32)\n",
    "    Y_test = Y_test.astype(np.int32)\n",
    "\n",
    "    with configuration.using_config('train', False):\n",
    "        y_calc = model(X_test)\n",
    "    # y_arr = np.array([i.data for i in y_calc])\n",
    "    # y_pred = np.argmax(y_arr, axis=1)\n",
    "    y_pred = np.argmax(y_calc.data, axis=1)\n",
    "\n",
    "    fg_fcst = np.r_[fg_fcst, y_pred]\n",
    "    fg_obs = np.r_[fg_obs, Y_test]\n",
    "    \n",
    "    if i == repeat:\n",
    "        break\n",
    "    \n",
    "    ## 学習\n",
    "#     DATA_O = DATA[learn_start:learn_end].reset_index(drop=True)\n",
    "#     DATA_S = Over_Sampling( DATA_O )\n",
    "#     Y = DATA_S[target]\n",
    "#     X = DATA_S[features]\n",
    "    Y = DATA[target][learn_start:learn_end]\n",
    "    X = DATA[features][learn_start:learn_end]\n",
    "\n",
    "    scaler.partial_fit( X )\n",
    "    X = scaler.transform( X )\n",
    "    X_train, X_dev, Y_train, Y_dev = train_test_split(X, Y, test_size=0.3, random_state=443)\n",
    "#     X_train = X\n",
    "#     Y_train = Y\n",
    "\n",
    "    ## Chainer用の変換\n",
    "    Y_train = Y_train.values\n",
    "    Y_dev = Y_dev.values\n",
    "\n",
    "    X_train = X_train.astype(np.float32)\n",
    "    X_dev = X_dev.astype(np.float32)\n",
    "\n",
    "    Y_train = Y_train.astype(np.int32)\n",
    "    Y_dev = Y_dev.astype(np.int32)\n",
    "\n",
    "    ## Chainerを走らせる\n",
    "    model = Model_D()\n",
    "    if i == 0:\n",
    "        serializers.load_npz(\"DNN_CLF_CAT3.npz\", model)\n",
    "    else:\n",
    "        serializers.load_npz(\"DNN_CLF_CAT3_online.npz\", model)\n",
    "    classifier = L.Classifier( model, lossfun=Loss_Func )\n",
    "#     optimizer = Adam()\n",
    "    optimizer = SGD()\n",
    "    optimizer.setup(classifier)\n",
    "\n",
    "    train_dataset = TupleDataset(X_train, Y_train)\n",
    "    dev_dataset = TupleDataset(X_dev, Y_dev)\n",
    "    test_dataset = TupleDataset(X_test, Y_test)\n",
    "\n",
    "    train_iterator = SerialIterator(train_dataset, batch_size=24, repeat=True)\n",
    "    dev_iterator = SerialIterator(dev_dataset, batch_size=24, shuffle=False, repeat=False)\n",
    "    test_iterator = SerialIterator(test_dataset, batch_size=24, shuffle=False, repeat=False)\n",
    "\n",
    "    updater = StandardUpdater(train_iterator, optimizer, loss_func=classifier)\n",
    "    stop_trigger = EarlyStoppingTrigger(check_trigger=(1, 'epoch'), monitor='dev/main/loss',\\\n",
    "                                        patients=1, max_trigger=(2, 'epoch'))\n",
    "\n",
    "    trainer = Trainer(updater, stop_trigger)\n",
    "    trainer.extend(Evaluator(dev_iterator, classifier), trigger=(1, 'epoch'), name=\"dev\")\n",
    "    trainer.extend(Evaluator(test_iterator, classifier), trigger=(1, 'epoch'), name=\"test\")\n",
    "    trainer.extend(PrintReport(['iteration', \"main/loss\", \"dev/main/loss\", \"test/main/loss\"]))\n",
    "    trainer.extend(SaveRestore(), trigger=MinValueTrigger('dev/main/loss', trigger=(1, 'epoch')))\n",
    "\n",
    "    logreport = LogReport(trigger=(1, 'epoch'))\n",
    "    trainer.extend(logreport)\n",
    "    trainer.run()\n",
    "\n",
    "    serializers.save_npz('DNN_CLF_CAT3_online.npz', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2016年：17429 - 26180\n",
    "# 2017年：26181 - \n",
    "print(classification_report(fg_obs[17429:26180], fg_fcst[17429:26180]))\n",
    "# pd.crosstab(fg_obs[17429:26180], fg_fcst[17429:26180])\n",
    "Category_Evaluation(fg_obs[17429:26180], fg_fcst[17429:26180])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2016年：17429 - 26180\n",
    "# 2017年：26181 - \n",
    "print(classification_report(fg_obs[26181:], fg_fcst[26181:]))\n",
    "# pd.crosstab(fg_obs[26181:], fg_fcst[26181:])\n",
    "Category_Evaluation(fg_obs[26181:], fg_fcst[26181:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### もっと浅くしてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_S(Chain):\n",
    "    def __init__(self):\n",
    "        super(Model_S, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.l1 = L.Linear(500)\n",
    "            self.l2 = L.Linear(500)\n",
    "            self.l3 = L.Linear(2)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        h = self.l1(x)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, ratio=0.5)\n",
    "\n",
    "        h = self.l2(h)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, ratio=0.5)\n",
    "\n",
    "        h = self.l3(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOSS計算時に重み付けをする\n",
    "def Loss_Func(x, t):\n",
    "    cw = np.array([1, 5]).astype(np.float32)\n",
    "    return F.softmax_cross_entropy(x, t, class_weight=cw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_learn = 17429\n",
    "\n",
    "DATA_O = DATA[0:pre_learn].reset_index(drop=True)\n",
    "DATA_S = Over_Sampling( DATA_O )\n",
    "Y = DATA_S[target]\n",
    "X = DATA_S[features]\n",
    "# Y = DATA[target][0:pre_learn]\n",
    "# X = DATA[features][0:pre_learn]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform( X )\n",
    "X_train, X_dev, Y_train, Y_dev = train_test_split(X, Y, test_size=0.3, random_state=443)\n",
    "\n",
    "## Chainer用の変換\n",
    "Y_train = Y_train.values\n",
    "Y_dev = Y_dev.values\n",
    "\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_dev = X_dev.astype(np.float32)\n",
    "\n",
    "Y_train = Y_train.astype(np.int32)\n",
    "Y_dev = Y_dev.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model_S()\n",
    "classifier = L.Classifier( model, lossfun=Loss_Func )\n",
    "optimizer = Adam()\n",
    "optimizer.setup(classifier)\n",
    "\n",
    "train_dataset = TupleDataset(X_train, Y_train)\n",
    "dev_dataset = TupleDataset(X_dev, Y_dev)\n",
    "# test_dataset = TupleDataset(X_test, Y_test)\n",
    "\n",
    "train_iterator = SerialIterator(train_dataset, batch_size=1024, repeat=True)\n",
    "dev_iterator = SerialIterator(dev_dataset, batch_size=1024, shuffle=False, repeat=False)\n",
    "# test_iterator = SerialIterator(test_dataset, batch_size=1024, shuffle=False, repeat=False)\n",
    "\n",
    "updater = StandardUpdater(train_iterator, optimizer, loss_func=classifier)\n",
    "stop_trigger = EarlyStoppingTrigger(check_trigger=(10, 'epoch'), monitor='dev/main/loss',\\\n",
    "                                    patients=10, max_trigger=(600, 'epoch'))\n",
    "\n",
    "trainer = Trainer(updater, stop_trigger)\n",
    "trainer.extend(Evaluator(dev_iterator, classifier), trigger=(1, 'epoch'), name=\"dev\")\n",
    "# trainer.extend(Evaluator(test_iterator, classifier), trigger=(1, 'epoch'), name=\"test\")\n",
    "trainer.extend(PrintReport(['iteration', \"main/loss\", \"dev/main/loss\"]))\n",
    "trainer.extend(SaveRestore(), trigger=MinValueTrigger('dev/main/loss', trigger=(1, 'epoch')))\n",
    "\n",
    "logreport = LogReport(trigger=(1, 'epoch'))\n",
    "trainer.extend(logreport)\n",
    "trainer.run()\n",
    "\n",
    "serializers.save_npz('DNN_CLF_FG3.npz', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with configuration.using_config('train', False):\n",
    "    y_calc = model(X_dev)\n",
    "# y_arr = np.array([i.data for i in y_calc])\n",
    "# y_pred = np.argmax(y_arr, axis=1)\n",
    "y_pred = np.argmax(y_calc.data, axis=1)\n",
    "print(classification_report(Y_dev, y_pred))\n",
    "# pd.crosstab(Y_dev, y_pred)\n",
    "OneCat_Evaluation(Y_dev, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### オンライン学習\n",
    "## ループの設定\n",
    "learn_hours = 30 * 24\n",
    "one_step = 30 * 24\n",
    "all_rows = DATA.shape[0]\n",
    "repeat = int( (all_rows - pre_learn) / one_step )\n",
    "\n",
    "fg_fcst = np.zeros( pre_learn )\n",
    "fg_obs = np.zeros( pre_learn )\n",
    "\n",
    "## 学習と予測ループ\n",
    "for i in range( repeat + 1 ):\n",
    "    print( \"loop {} times of {}\".format(i,repeat) )\n",
    "    \n",
    "    ## ループのパラメータ\n",
    "    fcst_start = pre_learn + i * one_step\n",
    "    fcst_end = fcst_start + one_step\n",
    "    if i == repeat:\n",
    "        fcst_end = all_rows\n",
    "    learn_end = fcst_end\n",
    "    learn_start = fcst_end - learn_hours\n",
    "#     print( fcst_start, fcst_end, learn_start, learn_end )\n",
    "    \n",
    "    ## 予測\n",
    "    Y_test = DATA[target][fcst_start:fcst_end]\n",
    "    X_test = DATA[features][fcst_start:fcst_end]\n",
    "    X_test = scaler.transform( X_test )\n",
    "\n",
    "    Y_test = Y_test.values\n",
    "    X_test = X_test.astype(np.float32)\n",
    "    Y_test = Y_test.astype(np.int32)\n",
    "\n",
    "    with configuration.using_config('train', False):\n",
    "        y_calc = model(X_test)\n",
    "    # y_arr = np.array([i.data for i in y_calc])\n",
    "    # y_pred = np.argmax(y_arr, axis=1)\n",
    "    y_pred = np.argmax(y_calc.data, axis=1)\n",
    "\n",
    "    fg_fcst = np.r_[fg_fcst, y_pred]\n",
    "    fg_obs = np.r_[fg_obs, Y_test]\n",
    "    \n",
    "    if i == repeat:\n",
    "        break\n",
    "    \n",
    "    ## 学習\n",
    "#     DATA_O = DATA[learn_start:learn_end].reset_index(drop=True)\n",
    "#     DATA_S = Over_Sampling( DATA_O )\n",
    "#     Y = DATA_S[target]\n",
    "#     X = DATA_S[features]\n",
    "    Y = DATA[target][learn_start:learn_end]\n",
    "    X = DATA[features][learn_start:learn_end]\n",
    "\n",
    "    scaler.partial_fit( X )\n",
    "    X = scaler.transform( X )\n",
    "    X_train, X_dev, Y_train, Y_dev = train_test_split(X, Y, test_size=0.3, random_state=443)\n",
    "#     X_train = X\n",
    "#     Y_train = Y\n",
    "\n",
    "    ## Chainer用の変換\n",
    "    Y_train = Y_train.values\n",
    "    Y_dev = Y_dev.values\n",
    "\n",
    "    X_train = X_train.astype(np.float32)\n",
    "    X_dev = X_dev.astype(np.float32)\n",
    "\n",
    "    Y_train = Y_train.astype(np.int32)\n",
    "    Y_dev = Y_dev.astype(np.int32)\n",
    "\n",
    "    ## Chainerを走らせる\n",
    "    model = Model_S()\n",
    "    if i == 0:\n",
    "        serializers.load_npz(\"DNN_CLF_FG3.npz\", model)\n",
    "    else:\n",
    "        serializers.load_npz(\"DNN_CLF_FG3_online.npz\", model)\n",
    "    classifier = L.Classifier( model, lossfun=Loss_Func )\n",
    "#     optimizer = Adam()\n",
    "    optimizer = SGD()\n",
    "    optimizer.setup(classifier)\n",
    "\n",
    "    train_dataset = TupleDataset(X_train, Y_train)\n",
    "    dev_dataset = TupleDataset(X_dev, Y_dev)\n",
    "    test_dataset = TupleDataset(X_test, Y_test)\n",
    "\n",
    "    train_iterator = SerialIterator(train_dataset, batch_size=24, repeat=True)\n",
    "    dev_iterator = SerialIterator(dev_dataset, batch_size=24, shuffle=False, repeat=False)\n",
    "    test_iterator = SerialIterator(test_dataset, batch_size=24, shuffle=False, repeat=False)\n",
    "\n",
    "    updater = StandardUpdater(train_iterator, optimizer, loss_func=classifier)\n",
    "    stop_trigger = EarlyStoppingTrigger(check_trigger=(1, 'epoch'), monitor='test/main/loss',\\\n",
    "                                        patients=3, max_trigger=(2, 'epoch'))\n",
    "\n",
    "    trainer = Trainer(updater, stop_trigger)\n",
    "    trainer.extend(Evaluator(dev_iterator, classifier), trigger=(1, 'epoch'), name=\"dev\")\n",
    "    trainer.extend(Evaluator(test_iterator, classifier), trigger=(1, 'epoch'), name=\"test\")\n",
    "    trainer.extend(PrintReport(['iteration', \"main/loss\", \"dev/main/loss\", \"test/main/loss\"]))\n",
    "    trainer.extend(SaveRestore(), trigger=MinValueTrigger('dev/main/loss', trigger=(1, 'epoch')))\n",
    "\n",
    "    logreport = LogReport(trigger=(1, 'epoch'))\n",
    "    trainer.extend(logreport)\n",
    "    trainer.run()\n",
    "\n",
    "    serializers.save_npz('DNN_CLF_FG3_online.npz', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2016年：17429 - 26180\n",
    "# 2017年：26181 - \n",
    "print(classification_report(fg_obs[17429:26180], fg_fcst[17429:26180]))\n",
    "# pd.crosstab(fg_obs[17429:26180], fg_fcst[17429:26180])\n",
    "OneCat_Evaluation(fg_obs[17429:26180], fg_fcst[17429:26180])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2016年：17429 - 26180\n",
    "# 2017年：26181 - \n",
    "print(classification_report(fg_obs[26181:], fg_fcst[26181:]))\n",
    "# pd.crosstab(fg_obs[26181:], fg_fcst[26181:])\n",
    "OneCat_Evaluation(fg_obs[26181:], fg_fcst[26181:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "classifier = L.Classifier( model, lossfun=Loss_Func )\n",
    "optimizer = Adam()\n",
    "optimizer.setup(classifier)\n",
    "\n",
    "train_dataset = TupleDataset(X_train, Y_train)\n",
    "dev_dataset = TupleDataset(X_dev, Y_dev)\n",
    "test_dataset = TupleDataset(X_test, Y_test)\n",
    "\n",
    "train_iterator = SerialIterator(train_dataset, batch_size=64, repeat=True)\n",
    "dev_iterator = SerialIterator(dev_dataset, batch_size=64, shuffle=False, repeat=False)\n",
    "test_iterator = SerialIterator(test_dataset, batch_size=64, shuffle=False, repeat=False)\n",
    "\n",
    "updater = StandardUpdater(train_iterator, optimizer, loss_func=classifier)\n",
    "stop_trigger = EarlyStoppingTrigger(check_trigger=(1, 'epoch'), monitor='dev/main/loss',\\\n",
    "                                    patients=10, max_trigger=(300, 'epoch'))\n",
    "\n",
    "trainer = Trainer(updater, stop_trigger)\n",
    "trainer.extend(Evaluator(dev_iterator, classifier), trigger=(1, 'epoch'), name=\"dev\")\n",
    "trainer.extend(Evaluator(test_iterator, classifier), trigger=(1, 'epoch'), name=\"test\")\n",
    "trainer.extend(PrintReport(['iteration', \"main/loss\", \"dev/main/loss\", \"test/main/loss\"]))\n",
    "trainer.extend(SaveRestore(), trigger=MinValueTrigger('dev/main/loss', trigger=(1, 'epoch')))\n",
    "\n",
    "logreport = LogReport(trigger=(1, 'epoch'))\n",
    "trainer.extend(logreport)\n",
    "trainer.run()\n",
    "\n",
    "serializers.save_npz('DNN_CLF_FG2', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 10,7\n",
    "log_df = pd.DataFrame(logreport.log)\n",
    "pd.DataFrame(log_df[[\"main/loss\", \"dev/main/loss\", \"test/main/loss\"]].values, columns=[\"main/loss\", \"dev/main/loss\", \"test/main/loss\"], index=log_df[\"iteration\"]).plot()\n",
    "log_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with configuration.using_config('train', False):\n",
    "    y_calc = model(X_dev)\n",
    "# y_arr = np.array([i.data for i in y_calc])\n",
    "# y_pred = np.argmax(y_arr, axis=1)\n",
    "y_pred = np.argmax(y_calc.data, axis=1)\n",
    "print(classification_report(Y_dev, y_pred))\n",
    "pd.crosstab(Y_dev, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneCat_Evaluation(Y_dev, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with configuration.using_config('train', False):\n",
    "    y_calc = model(X_test)\n",
    "# y_arr = np.array([i.data for i in y_calc])\n",
    "# y_pred = np.argmax(y_arr, axis=1)\n",
    "y_pred = np.argmax(y_calc.data, axis=1)\n",
    "print(classification_report(Y_test, y_pred))\n",
    "pd.crosstab(Y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneCat_Evaluation(Y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
